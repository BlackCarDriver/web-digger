
# url 种子, （入口）（默认为"https://tieba.baidu.com"）
url_seed = "https://tieba.baidu.com/f?kw=%E6%9D%8E%E6%AF%85"

# 仅爬取以这个字符串为前缀的url,用于过滤部分url,空时不过滤  (默认为空)
url_prefix = ""

# 用于标识特别的url,空时无标识作用 (默认为空)
url_must_contain = "j_th_tit"

# 用于标识与 url_seed同级别页面的切换链接,如跳转下一页的链接 （默认为空）
url_nextpage = "pagination-item"

# 搜寻策略，bfd, forward 或 list, (默认bfs)
travel_method = "bfd"

# url列表，仅当travel_method 为list时使用,爬取列表中的全部有效url (默认为空)
url_list = [
    "https://tieba.baidu.com/p/6175454635",
    "https://tieba.baidu.com/p/6175056749",
    "https://tieba.baidu.com/p/6176281029",
]

# 最多爬取多少个网页 (默认10)
max_pages_number = 100

# 同时下载图片的线程数 ,(默认为 1)
thread_numbers = 10

# 忽略小于多少 kb 一下的图片, (默认为 1)
min_img_kb = 10

# 忽略大于多少 mb 以上的图片, (默认为 10)
max_img_mb = 10

# 下载图片占用磁盘的最大空间, (默认100)
max_occupy_mb = 1000

# 最长的等待时间    (默认为10)
max_wait_time_s = 10

# 每进入一个新的地址前等待的时间 （默认为0）
sleep_time_s = 0

# 保存日志的目录
log_path = "D:\WorkPlace\Git WorPlace\web-digger\log"

# 保存图片的目录 （默认为程序运行的目录）
source_path = "D:\TempImg"
